{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('metis': conda)"
  },
  "interpreter": {
   "hash": "9ff5619d0b4d23b346007d49da5f2b2df0f81ce2bd1fd38999567ed2108bbf81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Import necessary packages\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import  NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Import created pipeline class\n",
    "from nlp_pipeline import nlp_pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#Load in pickled objects\n",
    "\n",
    "full_news_docs = pickle.load(open('full_news_docs','rb'))\n",
    "topic_model = pickle.load(open('topic_model','rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#Create dataframe with article sentiments\n",
    "\n",
    "sent_score_dict = {}\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for title in full_news_docs:\n",
    "    vs = analyzer.polarity_scores(title)\n",
    "    sent_score_dict[title] = vs['compound']\n",
    "\n",
    "sent_score_df = pd.DataFrame.from_dict(sent_score_dict, orient='index').reset_index()\n",
    "sent_score_df.columns = ['article','vader_compound']\n",
    "\n",
    "#Add general catergories\n",
    "def compound_sorter(score):\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score == 0:\n",
    "        return 0\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "\n",
    "sent_score_df['sentiment'] = sent_score_df['vader_compound'].apply(compound_sorter)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#Recommender function\n",
    "\n",
    "def article_opposite(input_query):\n",
    "\n",
    "    #Find sentiment\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    new_sentiment = compound_sorter(analyzer.polarity_scores(input_query)['compound']) #-1 negative, +1 positive\n",
    "\n",
    "    #Find topic\n",
    "    new_topic = topic_model.transform_new(input_query)\n",
    "    potential_article_return_list = pairwise_distances(new_topic,topic_model.topics,metric='cosine').argsort()\n",
    "    articles_to_return = []\n",
    "    already_added_1 = False\n",
    "    already_added_2 = False\n",
    "    if new_sentiment == 0:\n",
    "        for article in potential_article_return_list[0]:\n",
    "            article_sentiment = sent_score_df.iloc[article]['sentiment']\n",
    "            if (article_sentiment == 1) and (already_added_1 == False):\n",
    "                articles_to_return.append(article)\n",
    "                already_added_1 = True\n",
    "            elif (article_sentiment == -1) and (already_added_2 == False):\n",
    "                articles_to_return.append(article)\n",
    "                already_added_2 = True\n",
    "            elif (already_added_1 == True) and (already_added_2 == True):\n",
    "                return articles_to_return\n",
    "    elif new_sentiment == 1:\n",
    "        for article in potential_article_return_list[0]:\n",
    "            article_sentiment = sent_score_df.iloc[article]['sentiment']\n",
    "            if (article_sentiment == 0) and (already_added_1 == False):\n",
    "                articles_to_return.append(article)\n",
    "                already_added_1 = True\n",
    "            elif (article_sentiment == -1) and (already_added_2 == False):\n",
    "                articles_to_return.append(article)\n",
    "                already_added_2 = True\n",
    "            elif (already_added_1 == True) and (already_added_2 == True):\n",
    "                return articles_to_return\n",
    "    elif new_sentiment == -1:\n",
    "        for article in potential_article_return_list[0]:\n",
    "            article_sentiment = sent_score_df.iloc[article]['sentiment']\n",
    "            if (article_sentiment == 0) and (already_added_1 == False):\n",
    "                articles_to_return.append(article)\n",
    "                already_added_1 = True\n",
    "            elif (article_sentiment == 1) and (already_added_2 == False):\n",
    "                articles_to_return.append(article)\n",
    "                already_added_2 = True\n",
    "            elif (already_added_1 == True) and (already_added_2 == True):\n",
    "                return articles_to_return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#Test run\n",
    "\n",
    "recommended_articles = article_opposite(['vaccines'])\n",
    "article_1 = sent_score_df.iloc[recommended_articles[0]]['article']\n",
    "article_2 = sent_score_df.iloc[recommended_articles[1]]['article']\n",
    "print('Article 1: {art1}'.format(art1 = article_1))\n",
    "print('Article 2: {art2}'.format(art2 = article_2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 9129 56185 56186 ... 40576 40665     0]\n",
      "60438\n",
      "Article 1: A COVID-19 Hero\n",
      "Article 2: Graphic Australian Covid vaccine advertisement sparks outrage\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Pickle objects for easier transition to web app\n",
    "\n",
    "pickle.dump(sent_score_df, open('sent_score_df','wb')) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}